{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Basic libraries\n",
    "import sys, json, csv, re, string, nltk, math, urllib, io, unicodecsv, time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import *\n",
    "from collections import Counter\n",
    "tokenizer = RegexpTokenizer(r\"[a-zA-Z0-9À-ʯ']+\")\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords = True)\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Our methods and helpers\n",
    "from xmlOWL import *\n",
    "from SPARQLEndpoint import *\n",
    "import SDType\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Global Variables for this run\n",
    "linkInCountsMemo = dict()\n",
    "redirectLinkOf = dict()\n",
    "rangeLabel = None\n",
    "correctTypeObjectsDict = None # map entity --> abstract\n",
    "indexing = None\n",
    "relatedProperty = None\n",
    "correlatedProperty = None\n",
    "weightKeyword = 0\n",
    "tau = 0.9\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "def loadTestCases(filename):\n",
    "\ttestcases = list()\n",
    "\tinput_file = unicodecsv.DictReader(open(filename), encoding=\"utf-8\")\n",
    "\tfor row in input_file:\n",
    "\t\ttestcases.append({'s': row['s'], 'p': row['p'], 'o': row['o'], 'r':row['r']})\n",
    "\treturn testcases\n",
    "\n",
    "def processATestCase(rve, typeThreshold, method):\n",
    "\tprob = SDType.probOfType(rve['r'], rve['o'])\n",
    "\tif prob > typeThreshold:\n",
    "\t\tprint('Retain the old object', rve['o'], rve['r'], prob)\n",
    "\t\treturn None\n",
    "\telse:\n",
    "\t\tprint('Change the object', rve['o'], rve['r'], prob)\n",
    "\t\treturn getAnswerSortedList(rve['s'], rve['p'], rve['o'], method)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Data Structure\n",
    "class CandidateObject:\n",
    "\tdef __init__(self, uri, assoType, prop, relprop, prob):\n",
    "\t\tself.uri = uri\n",
    "\t\tself.associationType = assoType\n",
    "\t\tself.forProperty = prop\n",
    "\t\tself.relatedProperty = relprop\n",
    "\t\tself.conditionalProb = prob\n",
    "\t\t\n",
    "\t\tself.score = 0.0\n",
    "\t\tself.rankFrom = dict()\n",
    "\t\tself.linkInCount = findLinkInCount(prop, uri)\n",
    "\t\tself.doc = createDocFromEntity(uri)\n",
    "\n",
    "\t\tself.matchProfile = dict()\n",
    "\t\tself.bestLabelMatch = None\n",
    "\n",
    "class ClueText:\n",
    "\tdef __init__(self, lab, prop, relprop, prob):\n",
    "\t\tself.label = lab\n",
    "\t\tself.forProperty = prop\n",
    "\t\tself.relatedProperty = relprop\n",
    "\t\tself.conditionalProb = prob\n",
    "\t\tself.relatedness = None\n",
    "\t\tself.indicatorScore = None\n",
    "\t\tself.isCapitalKeyword = dict()\n",
    "\n",
    "\t\tlistOfWords = list(set(tokenizer.tokenize(lab)))\n",
    "\t\tlistOfWords = [word for word in listOfWords if word.lower() not in stopwords.words('english') and not word.lower().isdigit()]\n",
    "\t\tcapital = [word[0].isupper() for word in listOfWords]\n",
    "\t\tlistOfWords = [w.lower() for w in listOfWords]\n",
    "\t\tstemmedWords = [stemmer.stem(word) for word in listOfWords]\n",
    "\t\tfor idx, w in enumerate(stemmedWords):\n",
    "\t\t\tself.isCapitalKeyword[w] = capital[idx]\n",
    "\n",
    "\t\tfor idx, w in enumerate(listOfWords):\n",
    "\t\t\tif not any(sw in w for sw in stemmedWords):\n",
    "\t\t\t\tstemmedWords.append(w)\n",
    "\t\t\t\tself.isCapitalKeyword[w] = capital[idx]\n",
    "\n",
    "\t\tself.keywords = stemmedWords\n",
    "\t\tself.keywordsWeight = dict()\n",
    "\t\tself.maxLengthMatch = None\n",
    "\t\tself.matchedURI = dict()\n",
    "\t\tself.matchedURITotalLinkIn = dict()\n",
    "\t\tself.matchedURIMaxLinkIn = dict()\n",
    "\n",
    "\tdef calculateRelatedness(self, oDoc, useCondProb = True):\n",
    "\t\tkwInDoc = [kw for kw in self.keywords if kw in oDoc]\n",
    "\t\tif useCondProb:\n",
    "\t\t\tself.relatedness = self.conditionalProb * float(len(kwInDoc)+1)/(len(self.keywords)+1)\n",
    "\t\telse:\n",
    "\t\t\tself.relatedness = float(len(kwInDoc)+1)/(len(self.keywords)+1)\n",
    "\n",
    "\tdef calculateKeywordsWeight(self, oDoc):\n",
    "\t\tfor kw in self.keywords:\n",
    "\t\t\tif kw in oDoc and self.isCapitalKeyword[kw]:\n",
    "\t\t\t\tself.keywordsWeight[kw] = 1.0\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.keywordsWeight[kw] = weightKeyword\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Calculation Methods\n",
    "def getAnswerSortedList(s, p, o, method):\n",
    "\t# Check method name\n",
    "\tpossibleMethods = ['keyword', 'graph', 'combined', 'combinedScore']\n",
    "\tif method not in possibleMethods:\n",
    "\t\tprint(\"Error: Incorrect method command \" + method)\n",
    "\t\tprint(\"Possible choices of method are \" + str(possibleMethods))\n",
    "\t\tsys.exit(0)\n",
    "\n",
    "\t# Preparation\n",
    "\tglobal op, rangeLabel, correctTypeObjectsDict, indexing, relatedProperty, correlatedProperty\n",
    "\top = objectPropertyDict[p]\n",
    "\trangeLabel = getEnglishLabel(op.range)\n",
    "\tcorrectTypeObjectsDict = getCorrectTypeObjectsDict(op)\n",
    "\tindexing = doIndexing(correctTypeObjectsDict)\n",
    "\trelatedProperty, correlatedProperty = findRelatedProperty(p, op, threshold = tau)\n",
    "\t\n",
    "\t# Create Search Space\n",
    "\tcandidateObjects, clueList = getSearchSpace(s, p, o, op, relatedProperty, correlatedProperty, rangeLabel)\n",
    "\tif len(candidateObjects) == 0:\n",
    "\t\treturn []\t\n",
    "\n",
    "\t# Calculate Score\n",
    "\tif method.startswith('keyword'):\n",
    "\t\tsortedCandidateObjects = calculateScoreKeyword(candidateObjects, s, p, o, clueList)\n",
    "\telif method.startswith('graph'):\n",
    "\t\tsortedCandidateObjects = calculateScoreGraph(candidateObjects, s, p, o)\n",
    "\telif method == 'combined':\n",
    "\t\tsortedCandidateObjects = calculateScoreCombineMethod(candidateObjects, s, p, o, clueList)\n",
    "\telif method == 'combinedScore':\n",
    "\t\tsortedCandidateObjects = calculateScoreCombineScoreMethod(candidateObjects, s, p, o, clueList)\n",
    "\treturn sortedCandidateObjects\n",
    "\n",
    "def calculateScoreGraph(candidateObjects, s, p, o): # Use graph structure\n",
    "\tref = o \n",
    "\tquery = \"\"\"\n",
    "\tSELECT ?o (COUNT (DISTINCT ?o1) as ?cnt) WHERE {\n",
    "\t{ ?o ?p1 ?o1 } UNION  { ?o1 ?p1 ?o } .\n",
    "\t{ <%s> ?p2 ?o1 } UNION  { ?o1 ?p2 <%s> } .\n",
    "\t?o a <%s>.\n",
    "\t?o1 a owl:Thing.\n",
    "\tFILTER (?p1 != rdf:type && ?p2 != rdf:type).\n",
    "\t} GROUP BY ?o  ORDER BY DESC(?cnt)\n",
    "\t\"\"\" % (ref,ref,op.range)\n",
    "\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\tfor row in nrows:\n",
    "\t\tif row['o']['value'] in candidateObjects:\n",
    "\t\t\tcandidateObjects[row['o']['value']].score = float(row['cnt']['value'])\n",
    "\tfor obj in candidateObjects.values():\n",
    "\t\tif '3' in obj.associationType:\n",
    "\t\t\tobj.score += 1 # for 1 hob path\n",
    "\n",
    "\tsortedCandidateObjects = candidateObjects.values()\n",
    "\tsortedCandidateObjects.sort(key = lambda x: (x.score,len(x.associationType), x.linkInCount), reverse = True)\n",
    "\treturn sortedCandidateObjects\n",
    "\n",
    "def calculateScoreKeyword(candidateObjects, s, p, o, clueList): # Use Keyword Search \n",
    "\tincorrectObjectLabel = o.replace('http://dbpedia.org/resource/', '').lower() \n",
    "\tincorrectObjectAllDoc = createDocFromEntity(o, use = \"allDoc\")\n",
    "\tfor key in clueList.keys():\n",
    "\t\tclue = clueList[key]\n",
    "\t\tclue.calculateRelatedness(incorrectObjectAllDoc, useCondProb = False)\n",
    "\t\tclue.calculateKeywordsWeight(incorrectObjectAllDoc)\n",
    "\t\tprint(clue.label, clue.relatedness)\n",
    "\t\tprint(clue.keywordsWeight)\n",
    "\n",
    "\tfor candidate in candidateObjects.values():\n",
    "\t\tdocWords = tokenize(candidate.doc)\n",
    "\t\tsumScore = 0.0\n",
    "\t\tfor key, clue in clueList.iteritems(): \n",
    "\t\t\tif sum(clue.keywordsWeight.values()) == 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tscore = 0.0\n",
    "\t\t\tfor kw in clue.keywords:\n",
    "\t\t\t\tif kw in docWords or kw in tokenize(candidate.uri.replace('http://dbpedia.org/resource/', '')):\n",
    "\t\t\t\t\tscore += clue.keywordsWeight[kw]\n",
    "\t\t\tsumScore += float((score + 1)) / (len(clue.keywords)+1)\n",
    "\n",
    "\t\tif '1' in candidate.associationType and candidate.conditionalProb > tau:\n",
    "\t\t\tif '3' in candidate.associationType or removeNamespace(candidate.uri).strip().lower().replace('_',' ') in incorrectObjectAllDoc:\n",
    "\t\t\t\tsumScore += 1\n",
    "\n",
    "\t\tcandidate.score = sumScore\n",
    "\n",
    "\tsortedCandidateObjects = candidateObjects.values()\n",
    "\tsortedCandidateObjects.sort(key = lambda x: (x.score,len(x.associationType), x.linkInCount), reverse = True)\n",
    "\treturn sortedCandidateObjects\n",
    "\n",
    "def calculateScoreCombineMethod(candidateObjects, s, p, o, clueList): # Combine Graph Structure and Keyword Search\n",
    "\t# Score from graph method\n",
    "\tcalculateScoreGraph(candidateObjects, s, p, o)\n",
    "\ttempSort = candidateObjects.values()\n",
    "\ttempSort.sort(key = lambda x:(x.score,len(x.associationType), x.linkInCount), reverse = True)\n",
    "\tfor rank, item in enumerate(tempSort):\n",
    "\t\titem.rankFrom['graph'] = rank+1\n",
    "\t\titem.score = 0.0\n",
    "\n",
    "\t# Score from keyword method\n",
    "\tcalculateScoreKeyword(candidateObjects, s, p, o, clueList)\n",
    "\ttempSort = candidateObjects.values()\n",
    "\ttempSort.sort(key = lambda x:(x.score,len(x.associationType), x.linkInCount), reverse = True)\n",
    "\tfor rank, item in enumerate(tempSort):\n",
    "\t\titem.rankFrom['keyword'] = rank+1\n",
    "\t\t# Combine Score\n",
    "\t\titem.score = -((item.rankFrom['keyword'] + item.rankFrom['graph']) / 2.0)\n",
    "\n",
    "\tsortedCandidateObjects = candidateObjects.values()\n",
    "\tsortedCandidateObjects.sort(key = lambda x: (x.score,len(x.associationType), x.linkInCount), reverse = True)\n",
    "\treturn sortedCandidateObjects\n",
    "\n",
    "def calculateScoreCombineScoreMethod(candidateObjects, s, p, o, clueList): # Combine Graph Structure and Keyword Search\n",
    "\t# Score from graph method\n",
    "\tcalculateScoreGraph(candidateObjects, s, p, o)\n",
    "\tmaxGraphScore = max([x.score for x in candidateObjects.values()])\n",
    "\tfor item in candidateObjects.values():\n",
    "\t\tif maxGraphScore != 0:\n",
    "\t\t\titem.rankFrom['graph'] = 1.0*item.score/maxGraphScore\n",
    "\t\telse:\n",
    "\t\t\titem.rankFrom['graph'] = 0.0\n",
    "\t\titem.score = 0.0\n",
    "\n",
    "\t# Score from keyword method\n",
    "\tcalculateScoreKeyword(candidateObjects, s, p, o, clueList)\n",
    "\tmaxKeywordScore = max([x.score for x in candidateObjects.values()])\n",
    "\tfor item in candidateObjects.values():\n",
    "\t\tif maxKeywordScore != 0:\n",
    "\t\t\titem.rankFrom['keyword'] = 1.0*item.score/maxKeywordScore\n",
    "\t\telse:\n",
    "\t\t\titem.rankFrom['keyword'] = 0.0\n",
    "\t\t# Combine Score\n",
    "\t\titem.score = ((item.rankFrom['keyword'] + item.rankFrom['graph']) / 2.0)\n",
    "\n",
    "\tsortedCandidateObjects = candidateObjects.values()\n",
    "\tsortedCandidateObjects.sort(key = lambda x: (x.score,len(x.associationType), x.linkInCount), reverse = True)\n",
    "\treturn sortedCandidateObjects\n",
    "\n",
    "def getSearchSpace(s, p, o, op, relatedProperty, correlatedProperty, rangeLabel):\n",
    "\tcandidateObjects = dict()\n",
    "\t# print \"Related Property:\"\n",
    "\t# for r in relatedProperty.iterkeys():\n",
    "\t# \tprint r\n",
    "\t# print \"Correlated Property\"\n",
    "\t# for r in correlatedProperty.iterkeys():\n",
    "\t# \tprint r\n",
    "\t# --------------------- // Type 1 // ---------------------\n",
    "\tquery = \"\"\"\n",
    "\tSELECT ?a, ?p\n",
    "\tWHERE {\n",
    "\t\t<%s> ?p ?a.\n",
    "\t\t?a a <%s>.\n",
    "\t}\n",
    "\t\"\"\" % (s, op.range)\n",
    "\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\tfor objectRow in nrows:\n",
    "\t\tif objectRow['p']['value'] in relatedProperty:\n",
    "\t\t\tif objectRow['a']['value'] not in candidateObjects:\n",
    "\t\t\t\tnewCandidate = CandidateObject(uri = objectRow['a']['value'], assoType = '1', prop = p, relprop = objectRow['p']['value'], prob = relatedProperty[objectRow['p']['value']][5])\n",
    "\t\t\t\tcandidateObjects[objectRow['a']['value']] = newCandidate\n",
    "\t\t\telse:\n",
    "\t\t\t\tif candidateObjects[objectRow['a']['value']].conditionalProb < relatedProperty[objectRow['p']['value']][5]:\n",
    "\t\t\t\t\tcandidateObjects[objectRow['a']['value']].relatedProperty = objectRow['p']['value']\n",
    "\t\t\t\t\tcandidateObjects[objectRow['a']['value']].conditionalProb = relatedProperty[objectRow['p']['value']][5]\n",
    "\n",
    "\t# print 'Type1'\n",
    "\t# for key, val in candidateObjects.iteritems():\n",
    "\t# \tprint key, val.associationType, val.relatedProperty\n",
    "\t# --------------------- // Type 2 // ---------------------\n",
    "\t# 2.1 Find clues from correlatedProperty\n",
    "\tincorrectObjectLabel = getEnglishLabel(o)\n",
    "\tclueList = dict()\n",
    "\tclueList[incorrectObjectLabel] = ClueText(lab = incorrectObjectLabel, prop = p, relprop = p, prob = 1)\n",
    "\n",
    "\tif len(correlatedProperty) > 0:\n",
    "\t\tquery = \"\"\"\n",
    "\t\tSELECT ?a ?p\n",
    "\t\tWHERE { \n",
    "\t\t\t<%s> ?p ?a.\n",
    "\t\t\tFILTER NOT EXISTS {?a a <%s>.}\n",
    "\t\t\tFILTER (\n",
    "\t\t\"\"\" % (s, op.range)\n",
    "\n",
    "\t\tfilterProperty = [\"\"\"(?p = <%s>)\"\"\" % (key) for key in correlatedProperty.keys()]\n",
    "\t\tquery += \"\"\" || \"\"\".join(filterProperty)\n",
    "\t\tquery += \"\"\") }\"\"\"\n",
    "\t\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\t\t\n",
    "\t\tfor objectRow in nrows:\n",
    "\t\t\tif objectRow['a']['type'] == 'literal':\n",
    "\t\t\t\tif len(tokenizer.tokenize(objectRow['a']['value'])) > 0: # If the label has keywords\n",
    "\t\t\t\t\tclueList[objectRow['a']['value']] = ClueText(lab = objectRow['a']['value'], prop = p, relprop = objectRow['p']['value'], prob = correlatedProperty[objectRow['p']['value']][-1])\n",
    "\t\t\telif objectRow['a']['type'] == 'uri':\n",
    "\t\t\t\tlab = removeNamespace(objectRow['a']['value']) \n",
    "\t\t\t\tif len(tokenizer.tokenize(lab)) > 0: # If the label of uri has keywords\n",
    "\t\t\t\t\tclueList[lab] = ClueText(lab = lab, prop = p, relprop = objectRow['p']['value'], prob = correlatedProperty[objectRow['p']['value']][-1])\n",
    "\n",
    "\t# print '--> Clue Strings'\n",
    "\t# for key, value in clueList.iteritems():\n",
    "\t# \tprint value.label, value.relatedProperty, value.conditionalProb, value.keywords\n",
    "\n",
    "\t# 2.2 Find keywords from clues\n",
    "\t# print \"Clue Texts\"\n",
    "\tallKeywords = []\n",
    "\tfor key in clueList.keys():\n",
    "\t\tval = clueList[key]\n",
    "\t\tallKeywords.extend(val.keywords)\n",
    "\t\t# print key\n",
    "\tallKeywords = list(set(allKeywords))\n",
    "\n",
    "\tignoreWords = list(set(tokenizer.tokenize(rangeLabel)))\n",
    "\tignoreWords.extend([stemmer.stem(word) for word in ignoreWords])\n",
    "\tignoreWords = list(set(ignoreWords))\n",
    "\n",
    "\tallKeywords = [kw for kw in allKeywords if kw not in ignoreWords and kw not in rangeLabel and len(kw) >= 4]\n",
    "\t# print allKeywords\n",
    "\n",
    "\t# 2.3 Find objects from keywords\n",
    "\tif len(allKeywords) > 0:\n",
    "\t\t# Search from inverted index\n",
    "\t\tcList = [] # Candidate List\n",
    "\t\tfor kw in allKeywords:\n",
    "\t\t\tif kw not in indexing:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\tcList.extend([profile[0] for profile in indexing[kw]])\n",
    "\t\tcList = list(set(cList))\n",
    "\t\tfor uri in cList:\n",
    "\t\t\tif uri not in candidateObjects:\n",
    "\t\t\t\tnewCandidate = CandidateObject(uri = uri, assoType = '2', prop = p, relprop = None, prob = None)\n",
    "\t\t\t\tcandidateObjects[uri] = newCandidate\n",
    "\t\t\telse:\n",
    "\t\t\t\tcandidateObjects[uri].associationType += '2'\n",
    "\n",
    "\t# print 'Type2'\n",
    "\t# for key, val in candidateObjects.iteritems():\n",
    "\t# \tprint key, val.associationType, val.relatedProperty\n",
    "\n",
    "\t# --------------------- // Type 3 // ---------------------\n",
    "\tquery = \"\"\"\n",
    "\tSELECT ?p ?a\n",
    "\tWHERE {\n",
    "\t  { <%s> ?p ?a }\n",
    "\t  UNION\n",
    "\t  { ?a ?p <%s> }\n",
    "\t  ?a a <%s>.\n",
    "\t}\n",
    "\t\"\"\" % (o, o, op.range)\n",
    "\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\n",
    "\tfor objectRow in nrows:\n",
    "\t\tif objectRow['a']['value'] not in candidateObjects:\n",
    "\t\t\tnewCandidate = CandidateObject(uri = objectRow['a']['value'], assoType = '3', prop = p, relprop = objectRow['p']['value'], prob = None)\n",
    "\t\t\tcandidateObjects[objectRow['a']['value']] = newCandidate\n",
    "\t\telse:\n",
    "\t\t\tif '3' not in candidateObjects[objectRow['a']['value']].associationType:\n",
    "\t\t\t\tcandidateObjects[objectRow['a']['value']].associationType += '3'\n",
    "\n",
    "\t# print 'Type3'\n",
    "\t# for key, val in candidateObjects.iteritems():\n",
    "\t# \tprint key, val.associationType, val.relatedProperty\n",
    "\t# return candidateObjects, clueList\n",
    "\t# --------------------- // Filter Out // ---------------------\n",
    "\t# for uri in candidateObjects.keys():\n",
    "\t# \tif len(candidateObjects[uri].associationType) == 1 and candidateObjects[uri].linkInCount == 0:\n",
    "\t# \t\tcandidateObjects.pop(uri, None)\n",
    "\treturn candidateObjects, clueList\n",
    "\n",
    "def findRelatedProperty(uri, op, threshold):\n",
    "\t# Find related properties\n",
    "\tquery = \"\"\"\n",
    "\tSELECT ?p (COUNT(?s) AS ?count) \n",
    "\tWHERE {\n",
    "\t\t?s ?p ?o.\n",
    "\t\t?s <%s> ?o.\n",
    "\t\t?o a <%s>.\n",
    "\t} GROUP BY ?p\n",
    "\t\"\"\" % (uri, op.range)\n",
    "\tcooccurrences, cooccurrencesColumnHeader = SPARQLQuery(query)\n",
    "\tcooccurrencesProperty = [(prop['p']['value'], float(prop['count']['value'])) for prop in cooccurrences]\n",
    "\tif cooccurrencesProperty == []:\n",
    "\t\treturn [], []\t\n",
    "\tmaxCount = float(max(cooccurrencesProperty, key=lambda x: x[1])[1])\n",
    "\tcooccurrencesProperty = [(prop[0], prop[1], prop[1]/maxCount) for prop in cooccurrencesProperty]\n",
    "\n",
    "\t# Find confidence rate of related property\n",
    "\trelatedProperty = dict()\n",
    "\tcorrelatedProperty = dict()\n",
    "\tfor prop in cooccurrencesProperty:\n",
    "\t\tif prop[0] != uri:\n",
    "\t\t\tquery = \"\"\"\n",
    "\t\t\tSELECT (COUNT(?s) AS ?count) \n",
    "\t\t\tWHERE {\n",
    "\t\t\t\t?s <%s> ?o.\n",
    "\t\t\t\t?o a <%s>.\n",
    "\t\t\t}\n",
    "\t\t\t\"\"\" % (prop[0], op.range)\n",
    "\t\t\tcountThisProp, colhead = SPARQLQuery(query)\n",
    "\t\t\tcountThisProp = float(countThisProp[0]['count']['value'])\n",
    "\t\t\trelatedProperty[prop[0]] = (prop[0], prop[1], maxCount, countThisProp, prop[2], prop[1]/countThisProp)\n",
    "\t\t\tif prop[1]/countThisProp >= threshold:\n",
    "\t\t\t\tcorrelatedProperty[prop[0]] = relatedProperty[prop[0]]\n",
    "\t\t\t# Assume that set A is a set of triples with uri as a property, set B is a set of triples with a related property as a property\n",
    "\t\t\t# Each tuple in relatedProperty is in form of (relatedPropertyURI, n(A and B), n(A), n(B), P(B|A), P(A|B)) \n",
    "\t\t\t# Our confident weight for this property is P(A|B)\n",
    "\n",
    "\tprint('Related Property: '+('\\n').join(relatedProperty.keys()))\n",
    "\tprint('Correlated Property: '+('\\n').join(correlatedProperty.keys()))\n",
    "\treturn relatedProperty, correlatedProperty\n",
    "\n",
    "def getEnglishLabel(o):\n",
    "\tquery = \"\"\"\n",
    "\tSELECT ?lab\n",
    "\tWHERE {\n",
    "\t\t<%s> rdfs:label ?lab.\n",
    "\t\tFILTER (langmatches(lang(?lab), \"EN\"))\n",
    "\t} LIMIT 1\n",
    "\t\"\"\" % (o)\n",
    "\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\tif len(nrows) > 0:\n",
    "\t\treturn nrows[0]['lab']['value']\n",
    "\telse:\n",
    "\t\treturn removeNamespace(o).strip().replace('_',' ')\n",
    "\n",
    "def findLinkInCount(prop, objURI):\n",
    "\tif objURI not in linkInCountsMemo:\n",
    "\t\tquery = \"\"\"\n",
    "\t\tSELECT (COUNT(?s) AS ?count) \n",
    "\t\tWHERE {\n",
    "\t\t\t?s <%s> <%s>.\n",
    "\t\t}\n",
    "\t\t\"\"\" % (prop, objURI)\n",
    "\t\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\t\tlinkInCountsMemo[objURI] = float(nrows[0]['count']['value'])\n",
    "\treturn linkInCountsMemo[objURI]\n",
    "\n",
    "def createDocFromEntity(uri, use = \"abstract\"):\n",
    "\tif use == \"abstract\":\n",
    "\t\tif uri in correctTypeObjectsDict:\n",
    "\t\t\treturn correctTypeObjectsDict[uri]\n",
    "\t\telse:\n",
    "\t\t\tquery = \"\"\"\n",
    "\t\t\tSELECT ?abs\n",
    "\t\t\tWHERE{\n",
    "\t\t\t\t<%s> dbo:abstract ?abs.\n",
    "\t\t\t\tFILTER (langmatches(lang(?abs), \"EN\"))\n",
    "\t\t\t}\n",
    "\t\t\t\"\"\" % (uri)\n",
    "\t\t\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\t\t\tif len(nrows) > 0:\n",
    "\t\t\t\treturn nrows[0]['abs']['value'].lower()\n",
    "\t\t\telse: # return label\n",
    "\t\t\t\treturn uri.replace('http://dbpedia.org/resource/', '').lower() \n",
    "\telif use == \"allDoc\":\n",
    "\t\tdoc = uri\n",
    "\t\tquery = \"\"\"\n",
    "\t\tSELECT ?property ?hasValue ?isValueOf\n",
    "\t\tWHERE {\n",
    "\t\t  { <%s> ?property ?hasValue }\n",
    "\t\t  UNION\n",
    "\t\t  { ?isValueOf ?property <%s> }\n",
    "\t\t}\n",
    "\t\t\"\"\" % (uri, uri)\n",
    "\t\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\t\tfor row in nrows:\n",
    "\t\t\tif 'hasValue' in row:\n",
    "\t\t\t\tif 'xml:lang' not in row['hasValue'] or row['hasValue']['xml:lang'] == 'en':\n",
    "\t\t\t\t\tdoc += '\\n' + removeNamespace(row['property']['value'])\n",
    "\t\t\t\t\tdoc += ' : ' + removeNamespace(row['hasValue']['value'])\n",
    "\t\t\tif 'isValueOf' in row:\n",
    "\t\t\t\tif 'xml:lang' not in row['isValueOf'] or row['isValueOf']['xml:lang'] == 'en':\n",
    "\t\t\t\t\tdoc += '\\n' + removeNamespace(row['property']['value'])\n",
    "\t\t\t\t\tdoc += ' ; ' + removeNamespace(row['isValueOf']['value'])\t\t\t\n",
    "\t\treturn doc.lower()\n",
    "\n",
    "def getCorrectTypeObjectsDict(op, linkInCalculate = True):\n",
    "\tcorrectTypeObjectsDict = {}\t\n",
    "\ti = 0\n",
    "\twhile True:\n",
    "\t\tquery = \"\"\"\n",
    "\t\tSELECT ?a, ?abs\n",
    "\t\tWHERE {\n",
    "\t\t?a a <%s>.\n",
    "\t\tOPTIONAL {?a dbo:abstract ?abs.\n",
    "\t\tFILTER (langmatches(lang(?abs), \"EN\")) }\n",
    "\t\t} LIMIT 10000 OFFSET %d\n",
    "\t\t\"\"\" % (op.range, i*10000)\n",
    "\t\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\t\tif len(ncolumnHeader) == 0:\n",
    "\t\t\ti += 1\n",
    "\t\t\tcontinue\n",
    "\t\tif len(nrows) == 0:\n",
    "\t\t\tbreak\n",
    "\t\tfor row in nrows:\n",
    "\t\t\tif 'abs' in row:\n",
    "\t\t\t\tcorrectTypeObjectsDict[row['a']['value']] = row['abs']['value'].lower()\n",
    "\t\t\telse:\n",
    "\t\t\t\tcorrectTypeObjectsDict[row['a']['value']] = row['a']['value'].lower()\n",
    "\t\t\tlinkInCountsMemo[row['a']['value']] = 0\n",
    "\t\tprint('1', i)\n",
    "\t\ti += 1\n",
    "\n",
    "\tif linkInCalculate:\n",
    "\t\ti = 0\n",
    "\t\twhile True:\n",
    "\t\t\tquery = \"\"\"\n",
    "\t\t\tSELECT ?a, COUNT(?s) as ?cnt\n",
    "\t\t\tWHERE {\n",
    "\t\t\t?a a <%s>.\n",
    "\t\t\t?s <%s> ?a.\n",
    "\t\t\t} GROUP BY ?a LIMIT 10000 OFFSET %d\n",
    "\t\t\t\"\"\" % (op.range, op.uri, i*10000)\n",
    "\t\t\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\t\t\tif len(nrows) == 0:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tfor row in nrows:\n",
    "\t\t\t\tlinkInCountsMemo[row['a']['value']] = float(row['cnt']['value'])\n",
    "\t\t\tprint('2', i)\n",
    "\t\t\ti += 1\n",
    "\n",
    "\ti = 0\n",
    "\twhile True:\n",
    "\t\tquery = \"\"\"\n",
    "\t\tSELECT ?a, ?r\n",
    "\t\tWHERE {\n",
    "\t\t?a a <%s>.\n",
    "\t\t?r <http://dbpedia.org/ontology/wikiPageRedirects> ?a.\n",
    "\t\t} LIMIT 10000 OFFSET %d\n",
    "\t\t\"\"\" % (op.range, i*10000)\n",
    "\t\tnrows, ncolumnHeader = SPARQLQuery(query)\n",
    "\t\tif len(nrows) == 0:\n",
    "\t\t\tbreak\n",
    "\t\tfor row in nrows:\n",
    "\t\t\tredirectLinkOf[row['r']['value']] = row['a']['value']\n",
    "\t\tprint('3', i)\n",
    "\t\ti += 1\n",
    "\treturn correctTypeObjectsDict\n",
    "\n",
    "def removeNamespace(stri):\n",
    "\tnamespace = ['http://www.w3.org/2002/07/owl#',\n",
    "\t\t'http://www.w3.org/2001/XMLSchema#',\n",
    "\t\t'http://www.w3.org/2000/01/rdf-schema#',\n",
    "\t\t'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "\t\t'http://xmlns.com/foaf/0.1/',\n",
    "\t\t'http://purl.org/dc/elements/1.1/',\n",
    "\t\t'http://dbpedia.org/resource/',\n",
    "\t\t'http://dbpedia.org/property/',\n",
    "\t\t'http://dbpedia.org/ontology/',\n",
    "\t\t'http://www.w3.org/2004/02/skos/core#',\n",
    "\t\t'http://dbpedia.org/class/yago/',\n",
    "\t\t'http://',\n",
    "\t\t'www.',\n",
    "\t\t'wikipedia',\n",
    "\t\t'wiki'\n",
    "\t]\n",
    "\tfor ns in namespace:\n",
    "\t\tstri = stri.replace(ns, ' ') \n",
    "\treturn stri\n",
    "\n",
    "def doIndexing(docDict):\n",
    "\tinvertedIndex = dict()\n",
    "\tprint('NumEntities =',len(docDict))\n",
    "\ti = 0\n",
    "\tfor key in docDict.keys():\n",
    "\t\tif i%10000 == 0:\n",
    "\t\t\tprint('indexing', i)\n",
    "\t\tval = docDict[key]\n",
    "\t\tdoc = val.lower()\n",
    "\t\tdoc = tokenizer.tokenize(doc)\n",
    "\t\tdoc = [stemmer.stem(word) for word in doc]\n",
    "\t\tdocIndex = dict(Counter(doc))\n",
    "\t\tdocKeys = docIndex.keys()\n",
    "\t\tfor kw in docKeys:\n",
    "\t\t\tif kw in invertedIndex:\n",
    "\t\t\t\tinvertedIndex[kw].append((key, kw, docIndex[kw], float(docIndex[kw])/len(doc)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tinvertedIndex[kw] = [(key, kw, docIndex[kw], float(docIndex[kw])/len(doc))]\n",
    "\t\ti += 1\n",
    "\treturn invertedIndex\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "\tstemmed = []\n",
    "\tfor item in tokens:\n",
    "\t\tstemmed.append(stemmer.stem(item))\n",
    "\treturn stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "\t# tokens = nltk.word_tokenize(text)\n",
    "\ttokens = tokenizer.tokenize(text)\n",
    "\tstems = stem_tokens(tokens, stemmer)\n",
    "\treturn stems\n",
    "\n",
    "def translate_non_alphanumerics(to_translate, translate_to=u'_'):\n",
    "\tnot_letters_or_digits = u'!\"#%\\'()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "\ttranslate_table = dict((ord(char), translate_to) for char in not_letters_or_digits)\n",
    "\treturn to_translate.translate(translate_table)\n",
    "\n",
    "with open(\"wordsEn.txt\") as word_file:\n",
    "\tenglish_words = set(word.strip().lower() for word in word_file)\n",
    "\n",
    "def is_english_word(word):\n",
    "\treturn word.lower() in english_words\n",
    "\n",
    "op = objectPropertyDict['http://dbpedia.org/ontology/producer']\n",
    "# correctTypeObjectsDict = getCorrectTypeObjectsDict(op, linkInCalculate = False)\n",
    "# pickle.dump(correctTypeObjectsDict,open(\"correctTypeObjectsDict\"+getEnglishLabel(op.range)+\".pickle\",\"wb\"))\n",
    "# pickle.dump(redirectLinkOf,open(\"redirectLinkOf\"+getEnglishLabel(op.range)+\".pickle\",\"wb\"))\n",
    "correctTypeObjectsDict = pickle.load(open(\"./preprocessing/correctTypeObjectsDict\"+getEnglishLabel(op.range)+\".pickle\", \"rb\" ))\n",
    "indexing = doIndexing(correctTypeObjectsDict)\n",
    "pickle.dump(indexing,open(\"indexing\"+getEnglishLabel(op.range)+\".pickle\",\"wb\"))\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# testFilename = 'RVEsSampledServer300-20171229033026.csv'\n",
    "# method = 'combinedScore'\n",
    "\n",
    "# testcases = loadTestCases(testFilename)\n",
    "# testRange = range(len(testcases))[9:10]\n",
    "\n",
    "# f = open('output-'+testFilename[:-4]+'-'+method+ time.strftime(\"%Y%m%d%H%M%S\") +'.csv', 'a')\n",
    "# w = unicodecsv.writer(f, encoding='utf-8')\n",
    "# # w.writerow(['s','p','o','r'])\n",
    "# for k in testRange:\n",
    "# \trve = testcases[k]\n",
    "# \tprint('Testcase', k, rve['s'], rve['p'], rve['o'], rve['r'])\n",
    "# \tsortedCandidates = processATestCase(rve, typeThreshold = 0.4, method = method)\n",
    "# \tif sortedCandidates == []:\n",
    "# \t\tw.writerow([k, rve['s'], rve['p'], rve['o'], rve['r'], '-'])\n",
    "# \telif sortedCandidates is not None:\n",
    "# \t\tfor i in range(min(25, len(sortedCandidates))):\n",
    "# \t\t\tprint(i+1, sortedCandidates[i].uri, sortedCandidates[i].score) \n",
    "# \t\tw.writerow([k, rve['s'], rve['p'], rve['o'], rve['r']] + [candidate.uri for candidate in sortedCandidates[0:min(25, len(sortedCandidates))]])\n",
    "# \telse:\n",
    "# \t\tw.writerow([k, rve['s'], rve['p'], rve['o'], rve['r'], 'None'])\n",
    "# f.close()\n",
    "\n",
    "\n",
    "\n",
    "\t\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
